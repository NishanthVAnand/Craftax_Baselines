[=== Module python/3.9 loaded ===]
[=== Module cudatoolkit/12.6.0 loaded ===]
[=== Module python/3.9 loaded ===]
[=== Module cudatoolkit/12.6.0 loaded ===]
2025-04-03 18:15:48.519196: W external/xla/xla/service/gpu/nvptx_compiler.cc:765] The NVIDIA driver's CUDA version is 12.6 which is older than the ptxas CUDA version (12.8.93). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.55s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.71s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.89s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.46s/it]
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: nishanth127127 (aifgen) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/mila/a/anandnis/value_decomposition/v5/CoLLAs_2025/crafter_jax/Craftax_Baselines/wandb/run-20250403_181605-u052miuq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run LLM-Craftax-Symbolic-v1-1M
wandb: ⭐️ View project at https://wandb.ai/doina-precup/LLM-Play
wandb: 🚀 View run at https://wandb.ai/doina-precup/LLM-Play/runs/u052miuq
/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_inductor/compile_fx.py:194: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.
  warnings.warn(
ERROR:jax._src.callback:jax.pure_callback failed
Traceback (most recent call last):
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/callback.py", line 86, in pure_callback_impl
    return tree_util.tree_map(np.asarray, callback(*args))
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/callback.py", line 64, in __call__
    return tree_util.tree_leaves(self.callback_func(*args, **kwargs))
  File "/home/mila/a/anandnis/value_decomposition/v5/CoLLAs_2025/crafter_jax/Craftax_Baselines/llm_observation.py", line 72, in get_llm_obs
    hidden_states = llm_pretrained(**batch_tokens, output_hidden_states=True)[
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 574, in _fn
    return fn(*args, **kwargs)
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
    def new_forward(module, *args, **kwargs):
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 745, in _fn
    return fn(*args, **kwargs)
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 1184, in forward
    return compiled_fn(full_args)
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 323, in runtime_wrapper
    all_outs = call_func_at_runtime_with_args(
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/utils.py", line 126, in call_func_at_runtime_with_args
    out = normalize_as_list(f(args))
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 672, in inner_fn
    outs = compiled_fn(args)
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 490, in wrapper
    return compiled_fn(runtime_args)
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_inductor/output_code.py", line 466, in __call__
    return self.current_callable(inputs)
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_inductor/utils.py", line 2128, in run
    return model(new_inputs)
  File "/tmp/torchinductor_anandnis/iw/ciwmt54dhortbwad43j6n5qe7q33vpl2rmhb6hdx5ipwydmriqtc.py", line 4859, in call
    buf788 = empty_strided_cuda((256, s0, 128257), (128257*s0, 128257, 1), torch.float16)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 29.97 GiB. GPU 1 has a total capacity of 79.44 GiB of which 29.82 GiB is free. Including non-PyTorch memory, this process has 49.60 GiB memory in use. Of the allocated memory 47.64 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
E0403 19:10:28.736627 2995832 pjrt_stream_executor_client.cc:2985] Execution of replica 0 failed: INTERNAL: CustomCall failed: CpuCallback error: Traceback (most recent call last):
  File "/home/mila/a/anandnis/value_decomposition/v5/CoLLAs_2025/crafter_jax/Craftax_Baselines/ppo_llm.py", line 787, in <module>
  File "/home/mila/a/anandnis/value_decomposition/v5/CoLLAs_2025/crafter_jax/Craftax_Baselines/ppo_llm.py", line 688, in run_ppo
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/api.py", line 1214, in vmap_f
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/linear_util.py", line 192, in call_wrapped
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/pjit.py", line 327, in cache_miss
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/pjit.py", line 185, in _python_pjit_helper
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/core.py", line 2834, in bind
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/core.py", line 420, in bind_with_trace
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/interpreters/batching.py", line 433, in process_primitive
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/pjit.py", line 1895, in _pjit_batcher
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/core.py", line 2834, in bind
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/core.py", line 420, in bind_with_trace
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/core.py", line 921, in process_primitive
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/pjit.py", line 1635, in _pjit_call_impl
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/pjit.py", line 1614, in call_impl_cache_miss
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/pjit.py", line 1568, in _pjit_call_impl_python
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/profiler.py", line 335, in wrapper
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/interpreters/pxla.py", line 1244, in __call__
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/interpreters/mlir.py", line 2477, in _wrapped_callback
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/callback.py", line 228, in _callback
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/callback.py", line 89, in pure_callback_impl
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/callback.py", line 64, in __call__
  File "/home/mila/a/anandnis/value_decomposition/v5/CoLLAs_2025/crafter_jax/Craftax_Baselines/llm_observation.py", line 72, in get_llm_obs
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 584, in _fn
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 748, in _fn
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 1184, in forward
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 328, in runtime_wrapper
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/utils.py", line 135, in call_func_at_runtime_with_args
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 672, in inner_fn
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 490, in wrapper
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_inductor/output_code.py", line 468, in __call__
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_inductor/utils.py", line 2128, in run
  File "/tmp/torchinductor_anandnis/iw/ciwmt54dhortbwad43j6n5qe7q33vpl2rmhb6hdx5ipwydmriqtc.py", line 4861, in call
OutOfMemoryError: CUDA out of memory. Tried to allocate 29.97 GiB. GPU 1 has a total capacity of 79.44 GiB of which 29.82 GiB is free. Including non-PyTorch memory, this process has 49.60 GiB memory in use. Of the allocated memory 47.64 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/mila/a/anandnis/value_decomposition/v5/CoLLAs_2025/crafter_jax/Craftax_Baselines/ppo_llm.py", line 787, in <module>
    run_ppo(args)
  File "/home/mila/a/anandnis/value_decomposition/v5/CoLLAs_2025/crafter_jax/Craftax_Baselines/ppo_llm.py", line 688, in run_ppo
    out = train_vmap(rngs)
jaxlib.xla_extension.XlaRuntimeError: INTERNAL: CustomCall failed: CpuCallback error: Traceback (most recent call last):
  File "/home/mila/a/anandnis/value_decomposition/v5/CoLLAs_2025/crafter_jax/Craftax_Baselines/ppo_llm.py", line 787, in <module>
  File "/home/mila/a/anandnis/value_decomposition/v5/CoLLAs_2025/crafter_jax/Craftax_Baselines/ppo_llm.py", line 688, in run_ppo
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/api.py", line 1214, in vmap_f
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/linear_util.py", line 192, in call_wrapped
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/pjit.py", line 327, in cache_miss
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/pjit.py", line 185, in _python_pjit_helper
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/core.py", line 2834, in bind
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/core.py", line 420, in bind_with_trace
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/interpreters/batching.py", line 433, in process_primitive
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/pjit.py", line 1895, in _pjit_batcher
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/core.py", line 2834, in bind
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/core.py", line 420, in bind_with_trace
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/core.py", line 921, in process_primitive
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/pjit.py", line 1635, in _pjit_call_impl
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/pjit.py", line 1614, in call_impl_cache_miss
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/pjit.py", line 1568, in _pjit_call_impl_python
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/profiler.py", line 335, in wrapper
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/interpreters/pxla.py", line 1244, in __call__
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/interpreters/mlir.py", line 2477, in _wrapped_callback
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/callback.py", line 228, in _callback
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/callback.py", line 89, in pure_callback_impl
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/jax/_src/callback.py", line 64, in __call__
  File "/home/mila/a/anandnis/value_decomposition/v5/CoLLAs_2025/crafter_jax/Craftax_Baselines/llm_observation.py", line 72, in get_llm_obs
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 584, in _fn
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/accelerate/hooks.py", line 170, in new_forward
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 748, in _fn
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 1184, in forward
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 328, in runtime_wrapper
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/utils.py", line 135, in call_func_at_runtime_with_args
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 672, in inner_fn
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py", line 490, in wrapper
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_inductor/output_code.py", line 468, in __call__
  File "/home/mila/a/anandnis/crafter_jax/lib/python3.9/site-packages/torch/_inductor/utils.py", line 2128, in run
  File "/tmp/torchinductor_anandnis/iw/ciwmt54dhortbwad43j6n5qe7q33vpl2rmhb6hdx5ipwydmriqtc.py", line 4861, in call
OutOfMemoryError: CUDA out of memory. Tried to allocate 29.97 GiB. GPU 1 has a total capacity of 79.44 GiB of which 29.82 GiB is free. Including non-PyTorch memory, this process has 49.60 GiB memory in use. Of the allocated memory 47.64 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
